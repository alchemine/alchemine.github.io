---
title: MGSSL - Motif-based Graph Self-Supervised Learning for Molecular Property Prediction (NeurIPS 2021)
tags: Paper
---

# Paper
[Zhang, Z., Liu, Q., Wang, H., Lu, C., & Lee, C. K. (2021). Motif-based graph self-supervised learning for molecular property prediction. Advances in Neural Information Processing Systems, 34, 15870-15882.](https://proceedings.neurips.cc/paper_files/paper/2021/hash/85267d349a5e647ff0a9edcb5ffd1e02-Abstract.html)
- PDF: [https://proceedings.neurips.cc/paper_files/paper/2021/file/85267d349a5e647ff0a9edcb5ffd1e02-Paper.pdf](https://proceedings.neurips.cc/paper_files/paper/2021/file/85267d349a5e647ff0a9edcb5ffd1e02-Paper.pdf)
- Paper with code: [https://paperswithcode.com/paper/motif-based-graph-self-supervised-learning](https://paperswithcode.com/paper/motif-based-graph-self-supervised-learning)
- PyTorch code(official, ⭐86): [https://github.com/zaixizhang/MGSSL](https://github.com/zaixizhang/MGSSL)
- Citations: 113

<!--more-->
---

# Abstract
1. 분자 물성 예측(Predicting molecular properties) 분야의 다양한 분자 생성 및 예측 작업에서 Graph Neural Networks(GNNs)가 좋은 성과를 보여주고 있음.
2. Unlabeled molecule 데이터를 이용하는 기존의 self-supervised pre-training framework들은 대부분 node-level 혹은 graph-level에 집중하였으나, 이런 방법들은 subgraph 혹은 graph motif들에 있는 유의미한 정보들을 잡아내지 못함.
	- 가령, molecular graph에서 자주 나타나는 작용기들은 종종 중요한 정보를 가지고 있음.
3. 이런 문제를 해결하기 위해, **Motif-based Graph Self-supervised Learning (MGSSL)**을 제안.
	- **MGSSL: Self-supervised motif generation framework for GNNs**
4. MGSSL procedure.
	1. **Motif extraction**\
	Retrosynthesis(역합성)-based algorithm BRICS와 motif vocabulary의 개수를 조절하기 위한 추가적인 rule을 사용.
	2. **General motif-based generative pre-training framework**\
	GNNs에 topology(edge between motifs), label(motif) 예측 작업을 수행. (BFS 혹은 DFS 순서로 구현)
	3. **Multi-level self-supervised pre-training**\
	Molecule graph의 multi-scale 정보들을 같이 고려하기 위해 구현.
4. 여러가지 downstream 벤치마크에서 SOTA 보여줌.


---
# 1. Introduction
1. GNN과 그 variants들이 분자 물성 예측 분야에서 좋은 성능을 보여주고 있음.
2. 그러나 labeled molecules가 너무 적음.
3. 최근 NLP, CV 에서는 이러한 문제를 self-supervised learning(SSL)을 이용하여 해결하고 있음.
	- **Self-Supervised Learning**
		1. 먼저 unlabeled dataset으로 pre-training.
		2. Downstream 작업 수행.
4. GNNs의 SSL은 두 가지로 분류됨.
	1. Contrastive methods \
	동일한 그래프에서 나온 특성들(view)은 가깝게, 서로 다른 그래프의 것들은 멀리 떨어지도록 모델링.
	2. Predictive methods \
	데이터의 본질적인 특성을 이용하여 예측 작업을 수행. (e.g. atom와 edge 마스킹하고 예측하기, graph reconstruction 등)
5. 대부분의 기존 GNNs의 SSL은 graph motif로부터 유의미한 정보를 취하지 못하고 있으나, motif-level의 SSL이 필수적이다.
	1. Graph motif \
	자주 발생하는 중요한 subgraph 패턴으로, 전체 그래프에 대한 중요한 특성을 가지기도 함.
6. Motif-level SSL은 몇 가지 해결해야할 점들이 있음.
	1. 기존의 motif를 생성하는 방법들은 subgraph 구조의 일부(discrete count)만을 활용하고, 화학적 타당성을 간과하는 문제가 있음.
	2. 대부분의 그래프 생성 기술들은 motif-level이 아닌 node-by-node로 생성.
	3. Multi-level SSL 작업들을 잘 합치는 방법도 중요함.
		- Multi-level: atom-level, motif-level
7. 위의 문제들을 해결하기 위해, **Motif-based Graph Self-Supervised Learning(MGSSL)**과 **Multi-level self-supervised pre-training**을 제안하였음.
	1. BRICS 알고리즘과 motif vocabulary의 효율성을 높이기 위해 두 개의 rule을 추가하여 molecule graph를 motif tree로 변환.
	2. Topology, attribute 예측을 반복적으로 수행하여 molecular graph를 motif-by-motif로 생성.
	3. 
---
title: Dimensionality Reduction
tags: MachineLearning_Base
aside:
  toc: true
---

# Remarks
본 포스팅은 **Hands-On Machine Learning with Scikit-Learn & TensorFlow ([Auérlien Géron](/images/dt_files/https://github.com/ageron/handson-ml), [박해선(역)](/images/dt_files/https://github.com/rickiepark/handson-ml), 한빛미디어)** 를 참고하여 작성되었습니다.

<!--more-->
---

# 1. Curse of dimensionality
**데이터의 차원이 높을수록 overfitting 가능성 상승**

1. **대부분의 데이터가 경계(극단)와 매우 가까이 존재** \
단위 도형 안에서 무작위로 선택된 점이 경계선에서 0.001 이내에 위치할 가능성
    - $2$차원 : 0.4%
    - $10^6$차원 : 99.999999%
2. **대부분의 데이터가 서로 멀리 떨어져 있음** \
단위 도형 안에서 무작위로 선택된 두 점의 평균 거리
    - $2$차원: 0.52
    - $10^6$차원 : 408.25


# 2. Dimensionality reduction
## 2.1 Projection
대부분의 데이터들은 고차원 공간 안의 저차원 subspace 근처에 모여 있음
따라서, 적절한 subspace를 찾아 데이터들을 투영시키면 정보(variance)를 최대한 보존하면서 차원을 축소시킬 수 있음

### 2.1.1 PCA(Principal Component Analysis)
[Principal Component Analysis(PCA)](https://alchemine.github.io/2022/03/07/pca.html) 참조


### 2.1.2 Linear Discriminant Analysis(LDA)
Class를 가장 잘 구분하는 hyperplane을 학습하는 LDA의 특성을 이용하여, class를 멀리 떨어지도록 유지하도록 hyperplane에 데이터를 투영


## 2.2 Manifold learning
데이터가 놓여 있는 manifold를 modeling

**Manifold** \
국부적으로 $d$차원 hyperplane으로 보일 수 있는 $n$차원 공간의 일부 ($d<n$)
{:.success}

- 처리해야할 작업(regression, classification 등)이 manifold를 명확하게 할 수 있음

### 2.2.1 Locally Linear Embedding(LLE)
데이터의 cluster를 유지하도록 하는 비선형 차원 축소(NonLinear Dimensionlity Reduction, NLDR)

#### 2.2.1.1 Algorithm
1. **Locally linear modeling** \
각 sample($x_i$)에 대한 closest neighbors($x_j, \ j \in cn(i)$)의 linear combination을 modeling \
$W$: Sample들 간의 지역 선형 관계
$ \hat W = argmin_w \sum_i \big( x_i - \sum_{j \in cn(i)} w_{i,j} x_j \big)^2 $
2. **Dimensionality reduction** \
지역 선형 관계가 유지되도록 차원 축소 \
$ Y = argmin_y \sum_i \big( y_i - \sum_j \hat w_{i,j} y_j \big)^2 $

#### 2.2.1.2 Time complexity
1. $k$개의 cn을 탐색: $O(n log(n) d log(k))$
2. $W$ 최적화: $O(n d k^3)$
3. 차원 축소: $O(k n^2)$ (`method=standard`의 경우, 데이터가 많으면 사용하기 어려움)

#### 2.2.1.3 Code
{% highlight python linenos %}
from sklearn.datasets import load_digits
from sklearn.manifold import LocallyLinearEmbedding

X, _ = load_digits(return_X_y=True)
X.shape  # (1797, 64)

embedding = LocallyLinearEmbedding(n_components=2, n_jobs=-1)
X_transformed = embedding.fit_transform(X[:100])
X_transformed.shape  # (100, 2)
{% endhighlight %}


### 2.2.2 MultiDimensional Scaling(MDS)
Sample 간의 거리를 보존하면서 차원을 축소

{% highlight python linenos %}
from sklearn.datasets import load_digits
from sklearn.manifold import MDS

X, _ = load_digits(return_X_y=True)
X.shape  # (1797, 64)

embedding = MDS(n_components=2)
X_transformed = embedding.fit_transform(X[:100])
X_transformed.shape  # (100, 2)
{% endhighlight %}


### 2.2.3 Isomap
각 sample을 node로 간주하고, node간 최단 경로를 이루는 노드의 개수(geodesic distance)를 유지하면서 차원을 축소

{% highlight python linenos %}
from sklearn.datasets import load_digits
from sklearn.manifold import Isomap

X, _ = load_digits(return_X_y=True)
X.shape  # (1797, 64)

embedding = Isomap(n_components=2)
X_transformed = embedding.fit_transform(X[:100])
X_transformed.shape  # (100, 2)
{% endhighlight %}


### 2.2.4 t-SNE(t-distributed Stochastic Neighbor Embedding)
비슷한 sample은 가까이, 비슷하지 않은 sample은 멀리 떨어지도록 유지하면서 차원을 축소 \

- 고차원 공간에 있는 cluster를 시각화할 때 주로 사용

{% highlight python linenos %}
import numpy as np
from sklearn.manifold import TSNE

X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])
X_embedded = TSNE(n_components=2).fit_transform(X)
X_embedded.shape  # (4, 2)
{% endhighlight %}

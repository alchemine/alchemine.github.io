---
title: 9. Airflow
tags: Study_AWS-Data-Engineering
---

<!--more-->

# 1. 기존 데이터 파이프라인의 문제점
1. 실패 복구 \
언제 어떻게 다시 실행할 것인가?
2. 모니터링 \
잘 돌아가고 있는지 확인하기 어려움
3. 의존성 관리 \
데이터 파이프라인 간의 의존성이 있는 경우 상위 파이프라인이 잘 동작하고 있는지 파악이 어려움
4. 확장성 \
중앙화하여 관리하는 툴이 없어 분산된 환경에서 파이프라인들을 관리하기 어려움
5. 배포 \
새로운 workflow를 배포하기 어려움


# 2. Airflow
Airflow는 **workflow를 작성**하고 **스케줄링**하고 **모니터링**하는 작업을 **프로그래밍**할 수 있게 해주는 플랫폼

- Python 프로그래밍 가능
- 분산된 환경에서 확장성 있음
- 웹 대시보드 (UI) 제공
- 커스터마이징이 가능


# 3. Workflow
의존성(DAG)으로 연결된 작업(task)들의 집합


# 4. Airflow의 구성요소
1. 웹 서버 \
웹 대시보드 UI
2. 스케줄러 \
workflow가 언제 실행되는지 관리
3. Metastore \
메타데이터 관리
4. Executor \
테스크가 어떻게 실해오디는지 정의
5. Worker \
테스크를 실행하는 프로세스


# 5. Operator
작업(task)을 정의하는데 사용

1. Action Operators \
실제 연산을 수행
2. Transfer Operators \
데이터를 옮김
3. Sensor Operators \
테스크를 실행시킬 트리거를 기다림


# 6. Task
Operator를 실행시키면 task가 된다 \
Task = Operator instance


# 7. Airflow의 구조
## 7.1 One Node Architecture
Web Server
Metastore
Scheduler
Executor

1. DAG(task)를 작성하여 workflow를 생성
2. DAG를 실행시킬 때 scheduler는 DagRun 오브젝트(DAG instance)를 생성
3. DagRun 오브젝트는 task instance를 생성
4. Worker가 task 수행 후 DagRun의 상태를 "완료"로 바꿔놓는다


# 8. 실습
## 8.1 설치 및 계정 생성
### 8.1.1 설치 및 실행
```
$ pip install apache-airflow
$ airflow webserver
```

### 8.1.2 계정 생성
```
$ airflow users create --role Admin --username admin --email admin --firstname admin --lastname admin --password admin
```

## 8.2 Scheduler 생성
```
$ airflow scheduler
```


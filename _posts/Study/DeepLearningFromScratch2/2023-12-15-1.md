---
title: Chapter 2. 자연어와 단어의 분산 표현
tags: Study_DeepLearningFromScratch2
---

# Remarks
이 글은 [밑바닥부터 시작하는 딥러닝 2](https://www.hanbit.co.kr/media/books/book_view.html?p_code=B8950212853)을 정리한 내용을 담고 있습니다.

<!--more-->
---

# 2.1 자연어 처리란
**자연어 처리** \
인간의 일상언어(자연어)를 컴퓨터에게 이해시키기 위한 기술
{:.success}

1. 프로그래밍 언어: 의미가 어느정도 **고정** \
자연어: 의미와 형태가 유연하게 **변함**


## 2.1.1 단어의 의미
이번 장의 주제: **컴퓨터에게 '단어의 의미'를 이해시키는 방식**

- 단어의 의미를 표현하는 방법들
  1. 시소러스(thesaurus, 유의어 사전) 활용 기법
  2. 통계 기반 기법
  3. 추론 기반 기법


# 2.2 시소러스
사람이 **직접 정의**하여 단어의 의미를 나타내는 방법

## 2.2.1 WordNet
WordNet: 1985년부터 프린스턴 대학교에서 구축하기 시작한 시소러스
- 수많은 단어에 대한 동의어와 계층 구조 등의 관계가 정의되어 있음

## 2.2.2 시소러스의 문제점
1. 시대 변화에 대응하기 어려움 \
사람이 수작업으로 갱신해야함
2. 사람을 쓰는 비용이 큼 \
3. 단어의 미묘한 차이를 표현할 수 없음

이런 문제점들 때문에 **통계 기반 기법**과 **추론 기반 기법**을 사용


# 2.3 통계 기반 기법
**말뭉치(corpus)** \
자연어 처리를 염두에 두고 수집된 텍스트 데이터
{:.success}

**분산 표현(distributional representation)** \
단어의 벡터 표현
{:.success}

## 2.3.3 분포 가설
**분포 가설(distributional hypothesis)** \
단어 자체에는 의미가 없고, 해당 단어가 사용된 맥락(주변 단어)이 의미를 형성한다
{:.success}

## 2.3.4 동시발생 행렬
**통계 기반(statistical based) 기법** \
어떤 단어에 대하여 주변에 어떤 단어가 몇 번 등장하는지를 세어 집계하는 방법
{:.success}

```
you say goodbye and i say hello.

# you -> {you: 0, say: 1, goodbye: 0, and: 0, i: 0, hello: 0, .: 0}
you = [0, 1, 0, 0, 0, 0, 0]

# say -> {you: 1, say: 0, goodbye: 1, and: 0, i: 1, hello: 1, .: 0}
say = [1, 0, 1, 0, 1, 1, 0]
```

위와 같은 방식을 모든 단어에 적용하여 만든 행렬을 **동시발생 행렬(co-occurrence matrix, $C$)**이라 한다.

## 2.3.5 벡터 간 유사도
1. 코사인 유사도(cosine similarity) \
두 벡터가 가리키는 방향을 기준으로 사용 \
$similarity(x, y) = \frac{x \cdot y}{\mid\mid x \mid\mid \mid\mid y \mid\mid}$


# 2.4 통계 기반 기법 개선하기
## 2.4.1 상호정보량
**점별 상호정보량(Pointwise Mutual Information, PMI)** \
$PMI(x, y) = log \frac{P(x, y)}{P(x) P(y)} = \frac{N \cdot C(x, y)}{C(x) C(y)}$ \
$PPMI(x, y) = max(0, PMI(x, y))$

- $C$: co-occurence matrix
- $N$: size of corpus

말뭉치의 어휘 수가 증가함에 따라 각 **단어 벡터의 차원 수**도 증가한다는 문제점이 있음

## 2.4.2 차원 감소
